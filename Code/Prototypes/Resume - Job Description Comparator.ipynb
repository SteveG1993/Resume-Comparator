{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Job Description to Resume Comparator\n",
    "\n",
    "This program compares the words found in a job description to the words in a resume. The current version compares all words and gives a naive percentage match.\n",
    "\n",
    "Many employers use software to analyze applicant resumes. It is better to have as many terms in the resume that match those in the job description.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You resume matches at  22%\n",
      "Your resume is missing the following words (naive):  {'literally', 'turning', 'deep', 'absolute', 'directly', 'background', 'scientist', 'large', 'stability', 'providing', 'individual', 'user', 'behalf', 'scale', 'warehouse', 'like', 'primary', 'insight', 'knowledge', 'excellent', 'current', 'inc', 'upload', 'internal', 'seeking', 'pipeline', 'champion', 'this', 'array', 'bachelor', 'writing', 'responsibility', 'understand', 'computer', 'working', 'join', 'enables', 'degree', 'leader', 'power', 'build', 'id', 'taking', 'analyze', 'answer', 'creative', 'enhance', 'passionate', 'influence', 'identify', 'unstructured', 'job', 'our', 'engine', 'pipe', 'environment', 'highly', 'solution', 'find', 'well', 'structured', 'higher', 'presenting', 'are', 'experienced', 'question', 'play', 'news', 'matter', 'extracting', 'relevant', 'complex', 'similar', 'track', 'qualification', 'deliver', 'person', 'alexa', 'validate', 'ensure', 'music', 'description', 'best', 'tool', 'select', 'come', 'solver', 'transform', 'recognition', 'communicate', 'proficiency', 'finding', 'brain', 'name', 'extract', 'communicating', 'structure', 'excited', 'verbally', 'goal', 'record', 'information', 'manipulating', 'obsessed', 'use', 'basic', 'field', 'action', 'shaping', 'strong', 'perfect', 'ideal', 'file', 'echo', 'ownership', 'innovating', 'dsme', 'scenario', 'voice'}\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "import codecs\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "# NLTK's default english stopwords\n",
    "default_stopwords = stopwords.words('english')\n",
    "\n",
    "#File Locations\n",
    "\n",
    "document_folder = '../data/'\n",
    "resume_file = document_folder + 'resume.txt'\n",
    "job_description_file = document_folder + 'job_description.txt'\n",
    "custom_stopwords_file = document_folder + 'custom_stopwords.txt'\n",
    "\n",
    "custom_stopwords = codecs.open(custom_stopwords_file, 'r', 'utf-8').read().splitlines()\n",
    "all_stopwords = list(map(str.lower,set(default_stopwords + custom_stopwords)))\n",
    "                        \n",
    "minimum_word_length = 2\n",
    "\n",
    "desired_parts_of_speach = set(['NN'\n",
    "                   ,'NNP'\n",
    "                   ,'NNS'\n",
    "                   ,'NNPS']\n",
    "                 )\n",
    "\n",
    "\n",
    "\n",
    "def process_text(text,stopwords,pos='',lemmatizer=None):\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = pos_tag(tokens)\n",
    "    lem = lemmatizer\n",
    "\n",
    "    if len(pos)>0:\n",
    "        words = [w for w,pos in tags if pos in pos]\n",
    "        \n",
    "    words = [t for t in tokens if t.isalpha()]\n",
    "    words = [w for w in words if len(w)>=minimum_word_length]\n",
    "    words = [w for w in words if not w.isnumeric()]\n",
    "    words = [w for w in words if w not in all_stopwords]\n",
    "    words = [w.lower() for w in words]\n",
    "    \n",
    "    if lemmatizer is not None:\n",
    "        words = [lem.lemmatize(w) for w in words]\n",
    "#     words = [nouns_only(w) for w in words]\n",
    "#     words = map(nouns_only, words)\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f_resume=open(resume_file,'r',)\n",
    "f_desc = open(job_description_file,'r')\n",
    "\n",
    "raw_resume =f_resume.read()\n",
    "raw_desc = f_desc.read()\n",
    "\n",
    "resume_words = process_text(raw_resume,all_stopwords,desired_parts_of_speach,lem)\n",
    "job_words = process_text(raw_desc,all_stopwords,desired_parts_of_speach,lem)\n",
    "\n",
    "resume_set = set(resume_words)\n",
    "job_set = set(job_words)\n",
    "\n",
    "\n",
    "\n",
    "matching_words = resume_set.intersection(job_set)\n",
    "\n",
    "print ('You resume matches at ',\"{0:.0%}\".format(len(matching_words)/len(job_words)))\n",
    "\n",
    "print('Your resume is missing the following words (naive): ',job_set-resume_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'study', 'examine', 'canvas', 'psychoanalyse', 'dissect', 'canvass', 'analyse', 'take_apart', 'psychoanalyze', 'analyze', 'break_down'}\n",
      "set()\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wordnet.synsets(\"analyze\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "    if l.antonyms():\n",
    "     antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print(set(synonyms))\n",
    "print(set(antonyms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Improve Comparisons\n",
    "\n",
    "1. Exclude low information parts of speach like prepositions, conjunctions.\n",
    "2. Develop a list of skills.\n",
    "3. Break comparisons by parts of speech. (Nouns, verbs, adjectives).\n",
    "4. Look for key bigrams.\n",
    "5. Enumerate and compare sentence subjects\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: File Import of different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume - Job Description Comparator.ipynb\r\n",
      "Resume Comparator.ipynb\r\n",
      "resume_compare.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/steve/Projects_Local/Resume-Comparator/Code\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume - Job Description Comparator.ipynb\r\n",
      "Resume Comparator\r\n",
      "Resume Comparator.ipynb\r\n",
      "resume_compare.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
