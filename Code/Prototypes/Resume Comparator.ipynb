{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Job Description to Resume Comparator - FreqDist\n",
    "\n",
    "This program compares the words found in a job description to the words in a resume. The current version compares all words and gives a naive percentage match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You resume matches at  59%\n",
      "              Term  Frequency Frequency:1\n",
      "0             data         21        None\n",
      "1            alexa         12        None\n",
      "2         services          5        None\n",
      "3         learning          4        None\n",
      "4         business          4        None\n",
      "5       delivering          3        None\n",
      "6              sql          3        None\n",
      "7           python          3        None\n",
      "8          analyst          2        None\n",
      "9        analytics          2        None\n",
      "10        customer          2        None\n",
      "11        insights          2        None\n",
      "12            team          2        None\n",
      "13            echo          2        None\n",
      "14            deep          2        None\n",
      "15          engine          2        None\n",
      "16   communication          2        None\n",
      "17           large          2        None\n",
      "18             the          2        None\n",
      "19         machine          2        None\n",
      "20      scientists          2        None\n",
      "21      processing          2        None\n",
      "22        analysis          2        None\n",
      "23           using          2        None\n",
      "24         systems          2        None\n",
      "25            json          2        None\n",
      "26         scripts          2        None\n",
      "27         working          2        None\n",
      "28      experience          2        None\n",
      "29          senior          1        None\n",
      "..             ...        ...         ...\n",
      "149    information          1        None\n",
      "150     statistics          1        None\n",
      "151    engineering          1        None\n",
      "152       relevant          1        None\n",
      "153        complex          1        None\n",
      "154      scenarios          1        None\n",
      "155        similar          1        None\n",
      "156      scripting          1        None\n",
      "157       language          1        None\n",
      "158      knowledge          1        None\n",
      "159          rdbms          1        None\n",
      "160         mining          1        None\n",
      "161            etl          1        None\n",
      "162      warehouse          1        None\n",
      "163    proficiency          1        None\n",
      "164          excel          1        None\n",
      "165            vba          1        None\n",
      "166          pivot          1        None\n",
      "167         tables          1        None\n",
      "168          array          1        None\n",
      "169      functions          1        None\n",
      "170          power          1        None\n",
      "171         pivots          1        None\n",
      "172          files          1        None\n",
      "173  communicating          1        None\n",
      "174     presenting          1        None\n",
      "175            key          1        None\n",
      "176       findings          1        None\n",
      "177      technical          1        None\n",
      "178          teams          1        None\n",
      "\n",
      "[179 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from nltk import FreqDist\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# NLTK's default english stopwords\n",
    "default_stopwords = stopwords.words('english')\n",
    "\n",
    "#File Locations\n",
    "\n",
    "document_folder = '../data/'\n",
    "resume_file = document_folder + 'resume.txt'\n",
    "job_description_file = document_folder + 'job_description.txt'\n",
    "custom_stopwords_file = document_folder + 'custom_stopwords.txt'\n",
    "\n",
    "custom_stopwords = codecs.open(custom_stopwords_file, 'r', 'utf-8').read().splitlines()\n",
    "all_stopwords = set(default_stopwords + custom_stopwords)\n",
    "\n",
    "def process_text(text,stopwords):\n",
    "    tokens = word_tokenize(text)\n",
    "    words = [t for t in tokens if t.isalpha()]\n",
    "    words = [w for w in words if len(w)>1]\n",
    "    words = [w for w in words if not w.isnumeric()]\n",
    "    words = [w for w in words if w not in all_stopwords]\n",
    "    words = [w.lower() for w in words]\n",
    "    return FreqDist(words)\n",
    "\n",
    "\n",
    "f_resume=open(resume_file,'r',)\n",
    "f_desc = open(job_description_file,'r')\n",
    "\n",
    "raw_resume =f_resume.read()\n",
    "raw_desc = f_desc.read()\n",
    "\n",
    "resume_words = process_text(raw_resume,all_stopwords)\n",
    "job_words = process_text(raw_desc,all_stopwords)\n",
    "\n",
    "df_desc = pd.DataFrame.from_dict(job_words,orient='index')\n",
    "df_desc.columns = ['Frequency']\n",
    "df_desc.index.name = 'Term'\n",
    "\n",
    "\n",
    "df_resume = pd.DataFrame.from_dict(resume_words, orient='index')\n",
    "df_resume.columns = ['Frequency']\n",
    "df_resume.index.name = 'Term'\n",
    "\n",
    "\n",
    "df = pd.merge(df_desc,df_resume,how='left',left_index=True,right_index=True).fillna(0)\n",
    "\n",
    "df_matches = pd.merge(df_desc,df_resume,how='inner',left_index=True,right_index=True)\n",
    "df.sort_values(by='Frequency_x',ascending=False,inplace=True)\n",
    "# df.sort_values(by='Frequency_y',inplace=True,na_position='first')\n",
    "\n",
    "# df_missing = df[df['Frequency_y']==0]\n",
    "df_missing = df[df['Frequency_y']==0]\n",
    "df_missing.columns = ['In Job Description','In Resume']\n",
    "\n",
    "\n",
    "print ('You resume matches at ',\"{0:.0%}\".format(df_matches.size/df_desc.size))\n",
    "\n",
    "import pandasql as ps\n",
    "\n",
    "q1 = \"\"\"select * from \n",
    "        (SELECT df_desc.Term,df_desc.Frequency,df_resume.Frequency\n",
    "        from df_desc\n",
    "        left join df_resume on (lower(df_desc.Term) = lower(df_resume.Term)\n",
    "        and df_resume.Term is null)\n",
    "        order by 2 desc\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "print(ps.sqldf(q1, locals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_set = set(resume_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Improve Comparisons\n",
    "\n",
    "1. Exclude low information parts of speach like prepositions, conjunctions.\n",
    "2. Develop a list of skills.\n",
    "3. Break comparisons by parts of speech. (Nouns, verbs, adjectives).\n",
    "4. Look for key bigrams.\n",
    "5. Enumerate and compare sentence subjects\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: File Import of different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
