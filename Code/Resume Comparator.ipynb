{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Job Description to Resume Comparator\n",
    "\n",
    "This program compares the words found in a job description to the words in a resume. The current version compares all words and gives a naive percentage match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/steve/Projects_Local/Resume-Comparator/Code\r\n"
     ]
    }
   ],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You resume matches at  59%\n",
      "              Term  Frequency Frequency:1\n",
      "0             data         21        None\n",
      "1            alexa         12        None\n",
      "2         services          5        None\n",
      "3         learning          4        None\n",
      "4         business          4        None\n",
      "5       delivering          3        None\n",
      "6              sql          3        None\n",
      "7           python          3        None\n",
      "8          analyst          2        None\n",
      "9        analytics          2        None\n",
      "10        customer          2        None\n",
      "11        insights          2        None\n",
      "12            team          2        None\n",
      "13            echo          2        None\n",
      "14            deep          2        None\n",
      "15          engine          2        None\n",
      "16   communication          2        None\n",
      "17           large          2        None\n",
      "18             the          2        None\n",
      "19         machine          2        None\n",
      "20      scientists          2        None\n",
      "21      processing          2        None\n",
      "22        analysis          2        None\n",
      "23           using          2        None\n",
      "24         systems          2        None\n",
      "25            json          2        None\n",
      "26         scripts          2        None\n",
      "27         working          2        None\n",
      "28      experience          2        None\n",
      "29          senior          1        None\n",
      "..             ...        ...         ...\n",
      "149    information          1        None\n",
      "150     statistics          1        None\n",
      "151    engineering          1        None\n",
      "152       relevant          1        None\n",
      "153        complex          1        None\n",
      "154      scenarios          1        None\n",
      "155        similar          1        None\n",
      "156      scripting          1        None\n",
      "157       language          1        None\n",
      "158      knowledge          1        None\n",
      "159          rdbms          1        None\n",
      "160         mining          1        None\n",
      "161            etl          1        None\n",
      "162      warehouse          1        None\n",
      "163    proficiency          1        None\n",
      "164          excel          1        None\n",
      "165            vba          1        None\n",
      "166          pivot          1        None\n",
      "167         tables          1        None\n",
      "168          array          1        None\n",
      "169      functions          1        None\n",
      "170          power          1        None\n",
      "171         pivots          1        None\n",
      "172          files          1        None\n",
      "173  communicating          1        None\n",
      "174     presenting          1        None\n",
      "175            key          1        None\n",
      "176       findings          1        None\n",
      "177      technical          1        None\n",
      "178          teams          1        None\n",
      "\n",
      "[179 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#File Locations\n",
    "\n",
    "\n",
    "document_folder = '../data/'\n",
    "resume_file = document_folder + 'resume.txt'\n",
    "job_description_file = document_folder + 'job_description.txt'\n",
    "custom_stopwords_file = document_folder + 'custom_stopwords.txt'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from nltk import FreqDist\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# NLTK's default english stopwords\n",
    "default_stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "custom_stopwords = codecs.open(custom_stopwords_file, 'r', 'utf-8').read().splitlines()\n",
    "all_stopwords = set(default_stopwords + custom_stopwords)\n",
    "\n",
    "def process_text(text,stopwords):\n",
    "    tokens = word_tokenize(text)\n",
    "    words = [t for t in tokens if t.isalpha()]\n",
    "    words = [w for w in words if len(w)>1]\n",
    "    words = [w for w in words if not w.isnumeric()]\n",
    "    words = [w for w in words if w not in all_stopwords]\n",
    "    words = [w.lower() for w in words]\n",
    "    return FreqDist(words)\n",
    "\n",
    "\n",
    "f_resume=open(resume_file,'r',)\n",
    "f_desc = open(job_description_file,'r')\n",
    "\n",
    "raw_resume =f_resume.read()\n",
    "raw_desc = f_desc.read()\n",
    "\n",
    "resume_words = process_text(raw_resume,all_stopwords)\n",
    "job_words = process_text(raw_desc,all_stopwords)\n",
    "\n",
    "df_desc = pd.DataFrame.from_dict(job_words,orient='index')\n",
    "df_desc.columns = ['Frequency']\n",
    "df_desc.index.name = 'Term'\n",
    "\n",
    "\n",
    "df_resume = pd.DataFrame.from_dict(resume_words, orient='index')\n",
    "df_resume.columns = ['Frequency']\n",
    "df_resume.index.name = 'Term'\n",
    "\n",
    "\n",
    "df = pd.merge(df_desc,df_resume,how='left',left_index=True,right_index=True).fillna(0)\n",
    "\n",
    "df_matches = pd.merge(df_desc,df_resume,how='inner',left_index=True,right_index=True)\n",
    "df.sort_values(by='Frequency_x',ascending=False,inplace=True)\n",
    "# df.sort_values(by='Frequency_y',inplace=True,na_position='first')\n",
    "\n",
    "# df_missing = df[df['Frequency_y']==0]\n",
    "df_missing = df[df['Frequency_y']==0]\n",
    "df_missing.columns = ['In Job Description','In Resume']\n",
    "\n",
    "\n",
    "print ('You resume matches at ',\"{0:.0%}\".format(df_matches.size/df_desc.size))\n",
    "\n",
    "import pandasql as ps\n",
    "\n",
    "q1 = \"\"\"select * from \n",
    "        (SELECT df_desc.Term,df_desc.Frequency,df_resume.Frequency\n",
    "        from df_desc\n",
    "        left join df_resume on (lower(df_desc.Term) = lower(df_resume.Term)\n",
    "        and df_resume.Term is null)\n",
    "        order by 2 desc\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "print(ps.sqldf(q1, locals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Improve Comparisons\n",
    "\n",
    "1. Exclude low information parts of speach like prepositions, conjunctions.\n",
    "2. Develop a list of skills.\n",
    "3. Break comparisons by parts of speech. (Nouns, verbs, adjectives).\n",
    "4. Look for key bigrams.\n",
    "5. Enumerate and compare sentence subjects\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: File Import of different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Steven Gregoire\\nHingham, MA 02043 | (617) 733-6648 | steveg93@gmail.com\\nhttps://www.linkedin.com/in/sgregoire93/\\n\\thttps://github.com/SteveG1993\\n\\nData Scientist/Analyst seeks to enable a successful company to realize strategic market advantage through the delivery of intelligence-enabled products or services.\\n\\n•\\tAdvanced Analytics: SQL | Tableau | Jupyter\\n•\\tMachine Learning: Neural Networks | Time-series | NLP\\n•\\tProgramming: Python | .NET | T-SQL, PL/SQL\\n•\\tSoftware Engineering: SDLC | Git | Agile Scrum\\n•\\tCloud: Amazon Web Services, Google Cloud Platform\\n\\nWORK EXPERIENCE\\n\\nEnel X North America, Boston, MA\\nSenior Data Analytics Expert, 11/2018 - Present\\n\\n\\uf0a7\\tEnsured reliable and timely access to market pricing data for energy market advisory team. Sought out data from Independent System Operators (ISOs) and 3rd party data services. Ingested data using HTTP requests, FTP, and REST APIs.\\n\\uf0a7\\tEnhanced in-house applications and developed Excel models used for budgeting, forecasting, and risk management activities.\\n\\uf0a7\\tProvided ad-hoc analysis of budget data for Enel X strategic clients.\\n\\uf0a7\\tRedesigned System Peak-Predictor application used to notify customers of possible seasonal peak energy demand events. Worked closely with Enel X marketing group to integrate CSS and dynamic data elements into notification email.\\n\\nAutomatic Data Processing (ADP), Roseland, NJ\\nLead Applications Developer, 01/2003 – 09/2017\\n\\n\\uf0a7\\tDeveloped HR benefits enrollment, premium, and payroll reports for ADP’s Human Capital Management products using Business Objects and Oracle PL/SQL. Supported existing reports. Achieved a zero-defect backlog.\\n\\uf0a7\\tSecured new business by developing PeopleSoft to ADP interfaces.\\n\\uf0a7\\tLed a globally distributed Agile development team as a Scrum Master. Facilitated scrum ceremonies. Managed stakeholder expectations, cleared blockers, protected the team from distractions, and delivered consistently on time.\\n\\uf0a7\\tHands-on experience in all aspects of the software development life cycle from requirements to development, testing, deployment, and support. Participated in the company-wide transition from Waterfall to Agile methodologies.\\n\\nUnivision, Teaneck, NJ\\nSenior Report Developer, 05/2010 – 12/2012\\n\\n\\uf0a7\\tDeveloped customized reporting for accounts payable, accounts receivable/collections, and order management functions as part of an Oracle E-business implementation.\\n\\uf0a7\\tStreamlined the financial close process for the accounting team by publishing data sources using Tableau Server Business Intelligence platform.\\n\\uf0a7\\tRefined ETL scripts and stored procedure driven data transformations from advertising traffic systems resulting in fewer data feed issues and a quicker on-air to bill process\\n\\uf0a7\\tActed as point-of-contact for Tableau. Created FAQs and how-to documents. Conducted training sessions with Univision staff.\\n\\nERT, Boston, MA\\nData Delivery Engineer, 01/2008 – 09/2009\\n\\uf0a7\\tCreated custom SAS data sets from data gathered from Phase 3 clinical trials.\\n\\uf0a7\\tServed as technical SME for clinical study teams. Provided feasibility/time estimates for data related deliverables.\\n\\uf0a7\\tImplemented Oracle E-Business Suite. Created PL/SQL scripts to migrate data from Great Lakes accounting software to Oracle.\\n\\uf0a7\\tReduced costs by developing service-level reporting to detect projects with expenses exceeding contract maximums.\\n\\nEversource, Westwood, MA\\nSenior Research Analyst, 01/2003 – 10/2007\\n\\n\\uf0a7\\tProvided operational data analytics for electric smart meter pilot programs. Used meter age, data quality, read history to prioritize meter replacements.\\n\\uf0a7\\tEstablished report controls around key electricity metering and billing operations to improve billing timeliness for commercial/industrial accounts. Developed meter reading reports tracking electric/gas meter reading performance against established SLAs.\\n\\uf0a7\\tDesigned Subscription Automation System for delivering energy usage data to customers and other market participants. The software managed the fee-based subscription service generating over $100,000 annually.\\n\\nSKILLS\\n\\nLanguages: Oracle PL/SQL, T-SQL, Python, .NET 4.x, Java\\nDatabases: Microsoft SQL Server, Oracle 12, Microsoft Access, MongoDB, NoSQL databases, MySQL, Postgres, Amazon RDS, Other ANSI compliant RDBMS\\nSoftware: Tableau, Crystal Reports, SAP Business Objects, Oracle E-Business, SAS\\nOracle: Oracle PL/SQL, Stored Procedures, Functions, Triggers, Packages, Subqueries, Analytical Functions, Query optimization/ tuning using Explain Plan, ETL using Oracle BULK processing\\nOther: DOS, UNIX and Linux Scripting, Java, Object-oriented programming OOP, JSON, VBA, T-SQL, Excel pivot tables, Regex, CSS, HTML\\nCloud: Google BigQuery, GCP, Amazon Web Services Compute EC2\\nDevelopment: Toad, SQL Navigator, MongoDB Compass, Eclipse, Anaconda, Jupyter, VS Code\\nVersion Control: Git, Github, Bitbucket, Subversion (SVN), Crucible, Sourcetree\\nPlanning: Rally, Jira, Confluence\\nDeployment: Jenkins, Splunk\\nEDUCATION\\n\\nGeneral Assembly Data Science Immersive\\n\\uf0a7\\tCompleted a 480 hour, 12-week immersive program. Applied machine learning/deep learning algorithms to real-world problems.\\n\\uf0a7\\tTechniques\\n\\uf0a7\\tHypothesis Testing, Statistical Modelling, NLP, Natural Language Processing, Data Mining, Time-Series Analysis, Spatial Analysis, Web Scraping\\n\\uf0a7\\tMethods\\n\\uf0a7\\tMachine Learning, Supervised Learning, Regression, Classification, Generalized Linear Models, Linear Discriminant Analysis, Feature Selection, Support Vector Machines, SVM, Gradient Descent, Nearest Neighbors, Naïve Bayes, Decision Trees, Ensemble Methods, Supervised Neural Networks, Clustering, LSTM, Statistics\\n\\uf0a7\\tLanguages\\n\\uf0a7\\tPython, Scala (Databricks),\\n\\uf0a7\\tPackages\\n\\uf0a7\\tScikit-Learn, SciPy, TensorFlow, Keras, NLTK, Flask, NumPy, Pandas, Matplotlib, Bokeh\\n\\nUniversity of Rhode Island, Major: English, Minor: Speech Communication\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'access': 2,\n",
       "          'accounting': 2,\n",
       "          'accounts': 3,\n",
       "          'achieved': 1,\n",
       "          'acted': 1,\n",
       "          'activities': 1,\n",
       "          'adp': 3,\n",
       "          'advanced': 1,\n",
       "          'advantage': 1,\n",
       "          'advertising': 1,\n",
       "          'advisory': 1,\n",
       "          'age': 1,\n",
       "          'agile': 3,\n",
       "          'algorithms': 1,\n",
       "          'amazon': 3,\n",
       "          'america': 1,\n",
       "          'anaconda': 1,\n",
       "          'analysis': 4,\n",
       "          'analyst': 1,\n",
       "          'analytical': 1,\n",
       "          'analytics': 3,\n",
       "          'annually': 1,\n",
       "          'ansi': 1,\n",
       "          'apis': 1,\n",
       "          'application': 1,\n",
       "          'applications': 2,\n",
       "          'applied': 1,\n",
       "          'around': 1,\n",
       "          'aspects': 1,\n",
       "          'assembly': 1,\n",
       "          'automatic': 1,\n",
       "          'automation': 1,\n",
       "          'backlog': 1,\n",
       "          'bayes': 1,\n",
       "          'benefits': 1,\n",
       "          'bigquery': 1,\n",
       "          'bill': 1,\n",
       "          'billing': 2,\n",
       "          'bitbucket': 1,\n",
       "          'blockers': 1,\n",
       "          'bokeh': 1,\n",
       "          'boston': 2,\n",
       "          'budget': 1,\n",
       "          'budgeting': 1,\n",
       "          'bulk': 1,\n",
       "          'business': 4,\n",
       "          'capital': 1,\n",
       "          'ceremonies': 1,\n",
       "          'classification': 1,\n",
       "          'cleared': 1,\n",
       "          'clients': 1,\n",
       "          'clinical': 2,\n",
       "          'close': 1,\n",
       "          'closely': 1,\n",
       "          'cloud': 3,\n",
       "          'clustering': 1,\n",
       "          'code': 1,\n",
       "          'communication': 1,\n",
       "          'company': 1,\n",
       "          'compass': 1,\n",
       "          'completed': 1,\n",
       "          'compliant': 1,\n",
       "          'compute': 1,\n",
       "          'conducted': 1,\n",
       "          'confluence': 1,\n",
       "          'consistently': 1,\n",
       "          'contract': 1,\n",
       "          'control': 1,\n",
       "          'controls': 1,\n",
       "          'costs': 1,\n",
       "          'created': 3,\n",
       "          'crucible': 1,\n",
       "          'crystal': 1,\n",
       "          'css': 2,\n",
       "          'custom': 1,\n",
       "          'customers': 2,\n",
       "          'customized': 1,\n",
       "          'cycle': 1,\n",
       "          'data': 22,\n",
       "          'databases': 2,\n",
       "          'databricks': 1,\n",
       "          'decision': 1,\n",
       "          'deliverables': 1,\n",
       "          'delivered': 1,\n",
       "          'delivering': 1,\n",
       "          'delivery': 2,\n",
       "          'demand': 1,\n",
       "          'deployment': 2,\n",
       "          'descent': 1,\n",
       "          'designed': 1,\n",
       "          'detect': 1,\n",
       "          'developed': 4,\n",
       "          'developer': 2,\n",
       "          'developing': 2,\n",
       "          'development': 4,\n",
       "          'discriminant': 1,\n",
       "          'distractions': 1,\n",
       "          'distributed': 1,\n",
       "          'documents': 1,\n",
       "          'dos': 1,\n",
       "          'driven': 1,\n",
       "          'dynamic': 1,\n",
       "          'eclipse': 1,\n",
       "          'education': 1,\n",
       "          'electric': 1,\n",
       "          'electricity': 1,\n",
       "          'elements': 1,\n",
       "          'email': 1,\n",
       "          'enable': 1,\n",
       "          'enel': 3,\n",
       "          'energy': 3,\n",
       "          'engineer': 1,\n",
       "          'engineering': 1,\n",
       "          'english': 1,\n",
       "          'enhanced': 1,\n",
       "          'enrollment': 1,\n",
       "          'ensemble': 1,\n",
       "          'ensured': 1,\n",
       "          'ert': 1,\n",
       "          'established': 2,\n",
       "          'estimates': 1,\n",
       "          'etl': 2,\n",
       "          'events': 1,\n",
       "          'eversource': 1,\n",
       "          'exceeding': 1,\n",
       "          'excel': 2,\n",
       "          'existing': 1,\n",
       "          'expectations': 1,\n",
       "          'expenses': 1,\n",
       "          'experience': 1,\n",
       "          'expert': 1,\n",
       "          'explain': 1,\n",
       "          'facilitated': 1,\n",
       "          'faqs': 1,\n",
       "          'feature': 1,\n",
       "          'feed': 1,\n",
       "          'fewer': 1,\n",
       "          'financial': 1,\n",
       "          'flask': 1,\n",
       "          'forecasting': 1,\n",
       "          'ftp': 1,\n",
       "          'functions': 3,\n",
       "          'gathered': 1,\n",
       "          'gcp': 1,\n",
       "          'general': 1,\n",
       "          'generalized': 1,\n",
       "          'generating': 1,\n",
       "          'git': 2,\n",
       "          'github': 1,\n",
       "          'globally': 1,\n",
       "          'google': 2,\n",
       "          'gradient': 1,\n",
       "          'great': 1,\n",
       "          'gregoire': 1,\n",
       "          'group': 1,\n",
       "          'hingham': 1,\n",
       "          'history': 1,\n",
       "          'hour': 1,\n",
       "          'hr': 1,\n",
       "          'html': 1,\n",
       "          'http': 1,\n",
       "          'https': 2,\n",
       "          'human': 1,\n",
       "          'hypothesis': 1,\n",
       "          'immersive': 2,\n",
       "          'implementation': 1,\n",
       "          'implemented': 1,\n",
       "          'improve': 1,\n",
       "          'independent': 1,\n",
       "          'ingested': 1,\n",
       "          'integrate': 1,\n",
       "          'intelligence': 1,\n",
       "          'interfaces': 1,\n",
       "          'island': 1,\n",
       "          'isos': 1,\n",
       "          'issues': 1,\n",
       "          'java': 2,\n",
       "          'jenkins': 1,\n",
       "          'jira': 1,\n",
       "          'json': 1,\n",
       "          'jupyter': 2,\n",
       "          'keras': 1,\n",
       "          'key': 1,\n",
       "          'lakes': 1,\n",
       "          'language': 1,\n",
       "          'languages': 2,\n",
       "          'lead': 1,\n",
       "          'learning': 4,\n",
       "          'led': 1,\n",
       "          'life': 1,\n",
       "          'linear': 2,\n",
       "          'linux': 1,\n",
       "          'lstm': 1,\n",
       "          'ma': 4,\n",
       "          'machine': 3,\n",
       "          'machines': 1,\n",
       "          'major': 1,\n",
       "          'managed': 2,\n",
       "          'management': 3,\n",
       "          'market': 4,\n",
       "          'marketing': 1,\n",
       "          'master': 1,\n",
       "          'matplotlib': 1,\n",
       "          'maximums': 1,\n",
       "          'meter': 5,\n",
       "          'metering': 1,\n",
       "          'methodologies': 1,\n",
       "          'methods': 2,\n",
       "          'microsoft': 2,\n",
       "          'migrate': 1,\n",
       "          'mining': 1,\n",
       "          'minor': 1,\n",
       "          'modelling': 1,\n",
       "          'models': 2,\n",
       "          'mongodb': 2,\n",
       "          'mysql': 1,\n",
       "          'natural': 1,\n",
       "          'navigator': 1,\n",
       "          'naïve': 1,\n",
       "          'nearest': 1,\n",
       "          'neighbors': 1,\n",
       "          'networks': 2,\n",
       "          'neural': 2,\n",
       "          'new': 1,\n",
       "          'nj': 2,\n",
       "          'nlp': 2,\n",
       "          'nltk': 1,\n",
       "          'north': 1,\n",
       "          'nosql': 1,\n",
       "          'notification': 1,\n",
       "          'notify': 1,\n",
       "          'numpy': 1,\n",
       "          'objects': 2,\n",
       "          'oop': 1,\n",
       "          'operational': 1,\n",
       "          'operations': 1,\n",
       "          'operators': 1,\n",
       "          'oracle': 10,\n",
       "          'order': 1,\n",
       "          'other': 2,\n",
       "          'packages': 2,\n",
       "          'pandas': 1,\n",
       "          'part': 1,\n",
       "          'participants': 1,\n",
       "          'participated': 1,\n",
       "          'party': 1,\n",
       "          'payable': 1,\n",
       "          'payroll': 1,\n",
       "          'peak': 1,\n",
       "          'peoplesoft': 1,\n",
       "          'performance': 1,\n",
       "          'phase': 1,\n",
       "          'pilot': 1,\n",
       "          'pivot': 1,\n",
       "          'plan': 1,\n",
       "          'planning': 1,\n",
       "          'platform': 2,\n",
       "          'possible': 1,\n",
       "          'postgres': 1,\n",
       "          'premium': 1,\n",
       "          'present': 1,\n",
       "          'pricing': 1,\n",
       "          'prioritize': 1,\n",
       "          'problems': 1,\n",
       "          'procedure': 1,\n",
       "          'procedures': 1,\n",
       "          'process': 2,\n",
       "          'processing': 3,\n",
       "          'products': 2,\n",
       "          'program': 1,\n",
       "          'programming': 2,\n",
       "          'programs': 1,\n",
       "          'projects': 1,\n",
       "          'protected': 1,\n",
       "          'provided': 3,\n",
       "          'publishing': 1,\n",
       "          'python': 3,\n",
       "          'quality': 1,\n",
       "          'query': 1,\n",
       "          'quicker': 1,\n",
       "          'rally': 1,\n",
       "          'rdbms': 1,\n",
       "          'rds': 1,\n",
       "          'read': 1,\n",
       "          'reading': 2,\n",
       "          'realize': 1,\n",
       "          'redesigned': 1,\n",
       "          'reduced': 1,\n",
       "          'refined': 1,\n",
       "          'regex': 1,\n",
       "          'regression': 1,\n",
       "          'related': 1,\n",
       "          'reliable': 1,\n",
       "          'replacements': 1,\n",
       "          'report': 2,\n",
       "          'reporting': 2,\n",
       "          'reports': 4,\n",
       "          'requests': 1,\n",
       "          'requirements': 1,\n",
       "          'research': 1,\n",
       "          'rest': 1,\n",
       "          'resulting': 1,\n",
       "          'rhode': 1,\n",
       "          'risk': 1,\n",
       "          'roseland': 1,\n",
       "          'sap': 1,\n",
       "          'sas': 2,\n",
       "          'scala': 1,\n",
       "          'science': 1,\n",
       "          'scipy': 1,\n",
       "          'scraping': 1,\n",
       "          'scripting': 1,\n",
       "          'scripts': 2,\n",
       "          'scrum': 3,\n",
       "          'sdlc': 1,\n",
       "          'seasonal': 1,\n",
       "          'secured': 1,\n",
       "          'seeks': 1,\n",
       "          'selection': 1,\n",
       "          'senior': 3,\n",
       "          'served': 1,\n",
       "          'server': 2,\n",
       "          'service': 1,\n",
       "          'services': 4,\n",
       "          'sessions': 1,\n",
       "          'sets': 1,\n",
       "          'skills': 1,\n",
       "          'slas': 1,\n",
       "          'smart': 1,\n",
       "          'sme': 1,\n",
       "          'software': 5,\n",
       "          'sought': 1,\n",
       "          'sources': 1,\n",
       "          'sourcetree': 1,\n",
       "          'spatial': 1,\n",
       "          'speech': 1,\n",
       "          'splunk': 1,\n",
       "          'sql': 3,\n",
       "          'staff': 1,\n",
       "          'stakeholder': 1,\n",
       "          'statistical': 1,\n",
       "          'statistics': 1,\n",
       "          'steven': 1,\n",
       "          'stored': 2,\n",
       "          'strategic': 2,\n",
       "          'streamlined': 1,\n",
       "          'study': 1,\n",
       "          'subqueries': 1,\n",
       "          'subscription': 2,\n",
       "          'subversion': 1,\n",
       "          'successful': 1,\n",
       "          'suite': 1,\n",
       "          'supervised': 2,\n",
       "          'support': 2,\n",
       "          'supported': 1,\n",
       "          'svm': 1,\n",
       "          'svn': 1,\n",
       "          'system': 3,\n",
       "          'systems': 1,\n",
       "          'tableau': 4,\n",
       "          'tables': 1,\n",
       "          'team': 4,\n",
       "          'teams': 1,\n",
       "          'teaneck': 1,\n",
       "          'technical': 1,\n",
       "          'techniques': 1,\n",
       "          'tensorflow': 1,\n",
       "          'testing': 2,\n",
       "          'the': 1,\n",
       "          'time': 1,\n",
       "          'timeliness': 1,\n",
       "          'timely': 1,\n",
       "          'toad': 1,\n",
       "          'tracking': 1,\n",
       "          'traffic': 1,\n",
       "          'training': 1,\n",
       "          'transformations': 1,\n",
       "          'transition': 1,\n",
       "          'trees': 1,\n",
       "          'trials': 1,\n",
       "          'triggers': 1,\n",
       "          'tuning': 1,\n",
       "          'university': 1,\n",
       "          'univision': 2,\n",
       "          'unix': 1,\n",
       "          'usage': 1,\n",
       "          'used': 3,\n",
       "          'using': 5,\n",
       "          'vba': 1,\n",
       "          'vector': 1,\n",
       "          'version': 1,\n",
       "          'vs': 1,\n",
       "          'waterfall': 1,\n",
       "          'web': 3,\n",
       "          'westwood': 1,\n",
       "          'work': 1,\n",
       "          'worked': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
