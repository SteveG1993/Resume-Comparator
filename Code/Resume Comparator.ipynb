{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Job Description to Resume Comparator\n",
    "\n",
    "This program compares the words found in a job description to the words in a resume. The current version compares all words and gives a naive percentage match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Locations\n",
    "\n",
    "\n",
    "document_folder = '../data/'\n",
    "resume_file = document_folder + 'resume.txt'\n",
    "job_description_file = document_folder + 'job_description.txt'\n",
    "custom_stopwords_file = document_folder + 'custom_stopwords.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You resume matches at  59%\n",
      "               Term  Frequency Frequency:1\n",
      "0             alexa         12        None\n",
      "1          customer          2        None\n",
      "2          insights          2        None\n",
      "3              echo          2        None\n",
      "4              deep          2        None\n",
      "5            engine          2        None\n",
      "6             large          2        None\n",
      "7        scientists          2        None\n",
      "8           working          2        None\n",
      "9              dsme          1        None\n",
      "10              job          1        None\n",
      "11               id          1        None\n",
      "12      description          1        None\n",
      "13              are          1        None\n",
      "14          excited          1        None\n",
      "15       passionate          1        None\n",
      "16         directly          1        None\n",
      "17        influence          1        None\n",
      "18             user          1        None\n",
      "19               do          1        None\n",
      "20         champion          1        None\n",
      "21       innovating          1        None\n",
      "22           behalf          1        None\n",
      "23          turning          1        None\n",
      "24           action          1        None\n",
      "25             come          1        None\n",
      "26             join          1        None\n",
      "27        literally          1        None\n",
      "28          shaping          1        None\n",
      "29            voice          1        None\n",
      "..              ...        ...         ...\n",
      "96           ensure          1        None\n",
      "97         pipeline          1        None\n",
      "98        stability          1        None\n",
      "99      communicate          1        None\n",
      "100    stakeholders          1        None\n",
      "101         leaders          1        None\n",
      "102        verbally          1        None\n",
      "103         writing          1        None\n",
      "104           basic          1        None\n",
      "105  qualifications          1        None\n",
      "106        bachelor          1        None\n",
      "107          degree          1        None\n",
      "108          higher          1        None\n",
      "109           field          1        None\n",
      "110        computer          1        None\n",
      "111     information          1        None\n",
      "112        relevant          1        None\n",
      "113         complex          1        None\n",
      "114       scenarios          1        None\n",
      "115         similar          1        None\n",
      "116       knowledge          1        None\n",
      "117       warehouse          1        None\n",
      "118     proficiency          1        None\n",
      "119           array          1        None\n",
      "120           power          1        None\n",
      "121          pivots          1        None\n",
      "122           files          1        None\n",
      "123   communicating          1        None\n",
      "124      presenting          1        None\n",
      "125        findings          1        None\n",
      "\n",
      "[126 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "from nltk import FreqDist\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# NLTK's default english stopwords\n",
    "default_stopwords = stopwords.words('english')\n",
    "\n",
    "\n",
    "custom_stopwords = codecs.open(custom_stopwords_file, 'r', 'utf-8').read().splitlines()\n",
    "all_stopwords = set(default_stopwords + custom_stopwords)\n",
    "\n",
    "def process_text(text,stopwords):\n",
    "    tokens = word_tokenize(text)\n",
    "    words = [t for t in tokens if t.isalpha()]\n",
    "    words = [w for w in words if len(w)>1]\n",
    "    words = [w for w in words if not w.isnumeric()]\n",
    "    words = [w for w in words if w not in all_stopwords]\n",
    "    words = [w.lower() for w in words]\n",
    "    return FreqDist(words)\n",
    "\n",
    "\n",
    "f_resume=open(resume_file,'r',)\n",
    "f_desc = open(job_description_file,'r')\n",
    "\n",
    "raw_resume =f_resume.read()\n",
    "raw_desc = f_desc.read()\n",
    "\n",
    "resume_words = process_text(raw_resume,all_stopwords)\n",
    "job_words = process_text(raw_desc,all_stopwords)\n",
    "\n",
    "df_desc = pd.DataFrame.from_dict(job_words,orient='index')\n",
    "df_desc.columns = ['Frequency']\n",
    "df_desc.index.name = 'Term'\n",
    "\n",
    "\n",
    "df_resume = pd.DataFrame.from_dict(resume_words, orient='index')\n",
    "df_resume.columns = ['Frequency']\n",
    "df_resume.index.name = 'Term'\n",
    "\n",
    "\n",
    "df = pd.merge(df_desc,df_resume,how='left',left_index=True,right_index=True).fillna(0)\n",
    "\n",
    "df_matches = pd.merge(df_desc,df_resume,how='inner',left_index=True,right_index=True)\n",
    "df.sort_values(by='Frequency_x',ascending=False,inplace=True)\n",
    "# df.sort_values(by='Frequency_y',inplace=True,na_position='first')\n",
    "\n",
    "# df_missing = df[df['Frequency_y']==0]\n",
    "df_missing = df[df['Frequency_y']==0]\n",
    "df_missing.columns = ['In Job Description','In Resume']\n",
    "\n",
    "\n",
    "print ('You resume matches at ',\"{0:.0%}\".format(df_matches.size/df_desc.size))\n",
    "\n",
    "import pandasql as ps\n",
    "\n",
    "q1 = \"\"\"select * from \n",
    "        (SELECT df_desc.Term,df_desc.Frequency,df_resume.Frequency\n",
    "        from df_desc\n",
    "        left join df_resume on df_desc.Term = df_resume.Term\n",
    "        where df_resume.Term is null\n",
    "        order by 2 desc\n",
    "        )\n",
    "        \"\"\"\n",
    "\n",
    "print(ps.sqldf(q1, locals()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Improve Comparisons\n",
    "\n",
    "1. Exclude low information parts of speach like prepositions, conjunctions.\n",
    "2. Develop a list of skills.\n",
    "3. Break comparisons by parts of speech. (Nouns, verbs, adjectives).\n",
    "4. Look for key bigrams.\n",
    "5. Enumerate and compare sentence subjects\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: File Import of different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
