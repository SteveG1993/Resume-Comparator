{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Job Description to Resume Comparator\n",
    "\n",
    "This program compares the words found in a job description to the words in a resume. The current version compares all words and gives a naive percentage match.\n",
    "\n",
    "Many employers use software to analyze applicant resumes. It is better to have as many terms in the resume that match those in the job description.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You resume matches at  22%\n",
      "Your resume is missing the following words (naive):  {'literally', 'turning', 'deep', 'absolute', 'directly', 'background', 'scientist', 'large', 'stability', 'providing', 'individual', 'user', 'behalf', 'scale', 'warehouse', 'like', 'primary', 'insight', 'knowledge', 'excellent', 'current', 'inc', 'upload', 'internal', 'seeking', 'pipeline', 'champion', 'this', 'array', 'bachelor', 'writing', 'responsibility', 'understand', 'computer', 'working', 'join', 'enables', 'degree', 'leader', 'power', 'build', 'id', 'taking', 'analyze', 'answer', 'creative', 'enhance', 'passionate', 'influence', 'identify', 'unstructured', 'job', 'our', 'engine', 'pipe', 'environment', 'highly', 'solution', 'find', 'well', 'structured', 'higher', 'presenting', 'are', 'experienced', 'question', 'play', 'news', 'matter', 'extracting', 'relevant', 'complex', 'similar', 'track', 'qualification', 'deliver', 'person', 'alexa', 'validate', 'ensure', 'music', 'description', 'best', 'tool', 'select', 'come', 'solver', 'transform', 'recognition', 'communicate', 'proficiency', 'finding', 'brain', 'name', 'extract', 'communicating', 'structure', 'excited', 'verbally', 'goal', 'record', 'information', 'manipulating', 'obsessed', 'use', 'basic', 'field', 'action', 'shaping', 'strong', 'perfect', 'ideal', 'file', 'echo', 'ownership', 'innovating', 'dsme', 'scenario', 'voice'}\n"
     ]
    }
   ],
   "source": [
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "import codecs\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "\n",
    "# NLTK's default english stopwords\n",
    "default_stopwords = stopwords.words('english')\n",
    "\n",
    "#File Locations\n",
    "\n",
    "document_folder = '../data/'\n",
    "resume_file = document_folder + 'resume.txt'\n",
    "job_description_file = document_folder + 'job_description.txt'\n",
    "custom_stopwords_file = document_folder + 'custom_stopwords.txt'\n",
    "\n",
    "custom_stopwords = codecs.open(custom_stopwords_file, 'r', 'utf-8').read().splitlines()\n",
    "all_stopwords = list(map(str.lower,set(default_stopwords + custom_stopwords)))\n",
    "                        \n",
    "minimum_word_length = 2\n",
    "\n",
    "desired_parts_of_speach = set(['NN'\n",
    "                   ,'NNP'\n",
    "                   ,'NNS'\n",
    "                   ,'NNPS']\n",
    "                 )\n",
    "\n",
    "\n",
    "\n",
    "def process_text(text,stopwords,pos='',lemmatizer=None):\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = pos_tag(tokens)\n",
    "    lem = lemmatizer\n",
    "\n",
    "    if len(pos)>0:\n",
    "        words = [w for w,pos in tags if pos in pos]\n",
    "        \n",
    "    words = [t for t in tokens if t.isalpha()]\n",
    "    words = [w for w in words if len(w)>=minimum_word_length]\n",
    "    words = [w for w in words if not w.isnumeric()]\n",
    "    words = [w for w in words if w not in all_stopwords]\n",
    "    words = [w.lower() for w in words]\n",
    "    \n",
    "    if lemmatizer is not None:\n",
    "        words = [lem.lemmatize(w) for w in words]\n",
    "#     words = [nouns_only(w) for w in words]\n",
    "#     words = map(nouns_only, words)\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "f_resume=open(resume_file,'r',)\n",
    "f_desc = open(job_description_file,'r')\n",
    "\n",
    "raw_resume =f_resume.read()\n",
    "raw_desc = f_desc.read()\n",
    "\n",
    "resume_words = process_text(raw_resume,all_stopwords,desired_parts_of_speach,lem)\n",
    "job_words = process_text(raw_desc,all_stopwords,desired_parts_of_speach,lem)\n",
    "\n",
    "resume_set = set(resume_words)\n",
    "job_set = set(job_words)\n",
    "\n",
    "\n",
    "\n",
    "matching_words = resume_set.intersection(job_set)\n",
    "\n",
    "print ('You resume matches at ',\"{0:.0%}\".format(len(matching_words)/len(job_words)))\n",
    "\n",
    "print('Your resume is missing the following words (naive): ',job_set-resume_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['senior',\n",
       " 'data',\n",
       " 'analyst',\n",
       " 'dsme',\n",
       " 'alexa',\n",
       " 'data',\n",
       " 'services',\n",
       " 'job',\n",
       " 'id',\n",
       " 'services',\n",
       " 'inc',\n",
       " 'description',\n",
       " 'are',\n",
       " 'excited',\n",
       " 'passionate',\n",
       " 'delivering',\n",
       " 'advanced',\n",
       " 'analytics',\n",
       " 'directly',\n",
       " 'influence',\n",
       " 'alexa',\n",
       " 'user',\n",
       " 'do',\n",
       " 'champion',\n",
       " 'innovating',\n",
       " 'behalf',\n",
       " 'customer',\n",
       " 'turning',\n",
       " 'data',\n",
       " 'insights',\n",
       " 'action',\n",
       " 'come',\n",
       " 'join',\n",
       " 'alexa',\n",
       " 'data',\n",
       " 'services',\n",
       " 'team',\n",
       " 'data',\n",
       " 'sme',\n",
       " 'alexa',\n",
       " 'echo',\n",
       " 'literally',\n",
       " 'shaping',\n",
       " 'voice',\n",
       " 'recognition',\n",
       " 'alexa',\n",
       " 'name',\n",
       " 'amazon',\n",
       " 'cloud',\n",
       " 'service',\n",
       " 'brain',\n",
       " 'powers',\n",
       " 'echo',\n",
       " 'alexa',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'engine',\n",
       " 'answers',\n",
       " 'questions',\n",
       " 'plays',\n",
       " 'music',\n",
       " 'reads',\n",
       " 'news',\n",
       " 'our',\n",
       " 'goal',\n",
       " 'deliver',\n",
       " 'absolute',\n",
       " 'perfect',\n",
       " 'communication',\n",
       " 'customers',\n",
       " 'alexa',\n",
       " 'data',\n",
       " 'services',\n",
       " 'team',\n",
       " 'enables',\n",
       " 'alexa',\n",
       " 'deep',\n",
       " 'learning',\n",
       " 'providing',\n",
       " 'data',\n",
       " 'alexa',\n",
       " 'engine',\n",
       " 'alexa',\n",
       " 'data',\n",
       " 'services',\n",
       " 'seeking',\n",
       " 'experienced',\n",
       " 'data',\n",
       " 'analyst',\n",
       " 'strong',\n",
       " 'track',\n",
       " 'record',\n",
       " 'taking',\n",
       " 'ownership',\n",
       " 'delivering',\n",
       " 'large',\n",
       " 'scale',\n",
       " 'solutions',\n",
       " 'dynamic',\n",
       " 'business',\n",
       " 'environment',\n",
       " 'this',\n",
       " 'person',\n",
       " 'creative',\n",
       " 'problem',\n",
       " 'solver',\n",
       " 'obsessed',\n",
       " 'delivering',\n",
       " 'best',\n",
       " 'customer',\n",
       " 'well',\n",
       " 'highly',\n",
       " 'analytical',\n",
       " 'individual',\n",
       " 'excellent',\n",
       " 'communication',\n",
       " 'skills',\n",
       " 'the',\n",
       " 'alexa',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'scientists',\n",
       " 'identify',\n",
       " 'extract',\n",
       " 'transform',\n",
       " 'alexa',\n",
       " 'data',\n",
       " 'internal',\n",
       " 'tools',\n",
       " 'pipe',\n",
       " 'data',\n",
       " 'processing',\n",
       " 'the',\n",
       " 'ideal',\n",
       " 'background',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'extracting',\n",
       " 'manipulating',\n",
       " 'data',\n",
       " 'using',\n",
       " 'sql',\n",
       " 'python',\n",
       " 'primary',\n",
       " 'responsibilities',\n",
       " 'work',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'scientists',\n",
       " 'use',\n",
       " 'statistical',\n",
       " 'techniques',\n",
       " 'find',\n",
       " 'data',\n",
       " 'matters',\n",
       " 'analyze',\n",
       " 'understand',\n",
       " 'structured',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " 'systems',\n",
       " 'like',\n",
       " 'json',\n",
       " 'structures',\n",
       " 'build',\n",
       " 'python',\n",
       " 'sql',\n",
       " 'scripts',\n",
       " 'select',\n",
       " 'validate',\n",
       " 'upload',\n",
       " 'data',\n",
       " 'data',\n",
       " 'processing',\n",
       " 'application',\n",
       " 'system',\n",
       " 'support',\n",
       " 'enhance',\n",
       " 'current',\n",
       " 'scripts',\n",
       " 'data',\n",
       " 'software',\n",
       " 'engineers',\n",
       " 'ensure',\n",
       " 'pipeline',\n",
       " 'stability',\n",
       " 'communicate',\n",
       " 'analysis',\n",
       " 'insights',\n",
       " 'stakeholders',\n",
       " 'business',\n",
       " 'leaders',\n",
       " 'verbally',\n",
       " 'writing',\n",
       " 'basic',\n",
       " 'qualifications',\n",
       " 'bachelor',\n",
       " 'degree',\n",
       " 'higher',\n",
       " 'field',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'information',\n",
       " 'systems',\n",
       " 'statistics',\n",
       " 'engineering',\n",
       " 'relevant',\n",
       " 'business',\n",
       " 'analytics',\n",
       " 'large',\n",
       " 'complex',\n",
       " 'data',\n",
       " 'scenarios',\n",
       " 'python',\n",
       " 'similar',\n",
       " 'scripting',\n",
       " 'language',\n",
       " 'working',\n",
       " 'knowledge',\n",
       " 'rdbms',\n",
       " 'data',\n",
       " 'mining',\n",
       " 'using',\n",
       " 'sql',\n",
       " 'etl',\n",
       " 'data',\n",
       " 'warehouse',\n",
       " 'proficiency',\n",
       " 'excel',\n",
       " 'vba',\n",
       " 'pivot',\n",
       " 'tables',\n",
       " 'array',\n",
       " 'functions',\n",
       " 'power',\n",
       " 'pivots',\n",
       " 'experience',\n",
       " 'working',\n",
       " 'json',\n",
       " 'files',\n",
       " 'experience',\n",
       " 'communicating',\n",
       " 'presenting',\n",
       " 'key',\n",
       " 'findings',\n",
       " 'business',\n",
       " 'technical',\n",
       " 'teams']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: Improve Comparisons\n",
    "\n",
    "1. Exclude low information parts of speach like prepositions, conjunctions.\n",
    "2. Develop a list of skills.\n",
    "3. Break comparisons by parts of speech. (Nouns, verbs, adjectives).\n",
    "4. Look for key bigrams.\n",
    "5. Enumerate and compare sentence subjects\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: File Import of different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
